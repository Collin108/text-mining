{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "\n",
    "class Sentiment(object):\n",
    "    \"\"\"\n",
    "    文本情感计算类，支持导入自定义词典\n",
    "\n",
    "    默认使用知网Hownet词典进行情感分析\n",
    "        >>> from cnsenti import Sentiment\n",
    "        >>> senti = Sentiment()\n",
    "\n",
    "    统计文本中情感词个数，\n",
    "    返回的pos和neg是词语个数\n",
    "        >>>test_text= '我好开心啊，非常非常非常高兴！今天我得了一百分，我很兴奋开心，愉快，开心'\n",
    "        >>>senti.sentiment_count(test_text)\n",
    "        >>>{'words': 24, 'sentences': 2, 'pos': 4, 'neg': 0}\n",
    "\n",
    "    考虑强度副词(如\"非常\"，\"差不多\")对情感形容词的修饰作用，\n",
    "    和否定词对情感意义的反转作用。\n",
    "    返回的pos和neg是得分\n",
    "        >>>senti.sentiment_calculate(test_text)\n",
    "        >>>{'sentences': 2, 'words': 24, 'pos': 46.0, 'neg': 0.0}\n",
    "\n",
    "\n",
    "    使用自定义txt词典(建议utf-8编码)，\n",
    "    目前仅支持pos和neg两类词典，每行一个词语。\n",
    "    merge=True，cnsenti会融合自带的词典和用户导入的自定义词典；merge=False，cnsenti只使导入的自定义词典\n",
    "    其中pos和neg为txt词典文件路径，encoding为txt词典的编码方式\n",
    "    这里是utf-8编码的文件，初始化方式\n",
    "        >>>from cnsenti import Sentiment\n",
    "        >>>senti = Sentiment(pos='正面词典.txt', neg='负面词典.txt', merge=True, encoding='utf-8')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, merge=True, pos=None, neg=None, encoding='utf-8'):\n",
    "        \"\"\"\n",
    "        :pos 正面词典的txt文件\n",
    "        :neg 负面词典的txt文件\n",
    "        :merge 默认merge=True,即融合自带情感词典和自定义词典。merge=False，只使用自定义词典。\n",
    "        :encoding 词典txt文件的编码，默认为utf-8。如果是其他编码，该参数必须使用\n",
    "        \"\"\"\n",
    "        self.Poss = self.load_dict('pos.pkl')\n",
    "        self.Negs = self.load_dict('neg.pkl')\n",
    "\n",
    "        if pos:\n",
    "            if merge:\n",
    "                del self.Poss\n",
    "                self.Poss = self.load_diydict(file=pos, encoding=encoding)+self.load_dict('pos.pkl')\n",
    "                jieba.load_userdict(pos)\n",
    "\n",
    "            else:\n",
    "                del self.Poss\n",
    "                self.Poss = self.load_diydict(file=pos, encoding=encoding)\n",
    "                jieba.load_userdict(pos)\n",
    "\n",
    "\n",
    "        if neg:\n",
    "            if merge:\n",
    "                del self.Negs\n",
    "                self.Negs = self.load_diydict(file=neg, encoding=encoding)+self.load_dict('neg.pkl')\n",
    "                jieba.load_userdict(neg)\n",
    "            else:\n",
    "                del self.Negs\n",
    "                self.Negs = self.load_diydict(file=neg, encoding=encoding)\n",
    "                jieba.load_userdict(neg)\n",
    "\n",
    "        self.Denys = self.load_dict('deny.pkl')\n",
    "\n",
    "        self.Extremes = self.load_dict('extreme.pkl')\n",
    "        self.Verys = self.load_dict('very.pkl')\n",
    "        self.Mores = self.load_dict('more.pkl')\n",
    "        self.Ishs = self.load_dict('ish.pkl')\n",
    "\n",
    "    def load_dict(self, file):\n",
    "        \"\"\"\n",
    "        Sentiment内置的读取hownet自带pkl词典\n",
    "        :param file:  词典pkl文件\n",
    "        :return: 词语列表\n",
    "        \"\"\"\n",
    "        #pathchain = ['dictionary', 'hownet',file]\n",
    "        pathchain = ['hownet',file]\n",
    "        mood_dict_filepath = pathlib.Path('__file__').parent.joinpath(*pathchain)\n",
    "        dict_f = open(mood_dict_filepath, 'rb')\n",
    "        words = pickle.load(dict_f)\n",
    "        return words\n",
    "\n",
    "    def load_diydict(self, file, encoding):\n",
    "        \"\"\"\n",
    "        :param file:  自定义txt情感词典，其中txt文件每行只能放一个词\n",
    "        :param encoding:  txt文件的编码方式\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        text = open(file, encoding=encoding).read()\n",
    "        words = text.split('\\n')\n",
    "        words = [w for w in words if w]\n",
    "        return words\n",
    "\n",
    "\n",
    "    def sentiment_count(self, text):\n",
    "        \"\"\"\n",
    "        简单情感分析，未考虑强度副词、否定词对情感的复杂影响。仅仅计算各个情绪词出现次数(占比)\n",
    "        :param text:  中文文本字符串\n",
    "        :return: 返回情感信息，形如{'sentences': 2, 'words': 24, 'pos': 46.0, 'neg': 0.0}\n",
    "        \"\"\"\n",
    "        length, sentences, pos, neg = 0, 0, 0, 0\n",
    "        sentences = [s for s in re.split('[\\.。！!？\\?\\n;；]+', text) if s]\n",
    "        sentences = len(sentences)\n",
    "        words = jieba.lcut(text)\n",
    "        length = len(words)\n",
    "        for w in words:\n",
    "            if w in self.Poss:\n",
    "                pos+=1\n",
    "            elif w in self.Negs:\n",
    "                neg+=1\n",
    "            else:\n",
    "                pass\n",
    "        return {'words': length,  'sentences':sentences, 'pos':pos, 'neg':neg}\n",
    "\n",
    "\n",
    "    def judgeodd(self, num):\n",
    "        \"\"\"\n",
    "        判断奇数偶数。当情感词前方有偶数个否定词，情感极性方向不变。奇数会改变情感极性方向。\n",
    "        \"\"\"\n",
    "        if (num % 2) == 0:\n",
    "            return 'even'\n",
    "        else:\n",
    "            return 'odd'\n",
    "\n",
    "    def sentiment_calculate(self, text):\n",
    "        \"\"\"\n",
    "        考虑副词对情绪形容词的修饰作用和否定词的反转作用，\n",
    "        其中副词对情感形容词的情感赋以权重，\n",
    "        否定词确定情感值正负。\n",
    "\n",
    "        :param text:  文本字符串\n",
    "        :return: 返回情感信息，刑如{'sentences': 2, 'words': 24, 'pos': 46.0, 'neg': 0.0}\n",
    "        \"\"\"\n",
    "        sentences = [s for s in re.split('[\\.。！!？\\?\\n;；]+', text) if s]\n",
    "        wordnum = len(jieba.lcut(text))\n",
    "        count1 = []\n",
    "        count2 = []\n",
    "        for sen in sentences:\n",
    "            segtmp = jieba.lcut(sen)\n",
    "            i = 0  # 记录扫描到的词的位置\n",
    "            a = 0  # 记录情感词的位置\n",
    "            poscount = 0  # 积极词的第一次分值\n",
    "            poscount2 = 0  # 积极词反转后的分值\n",
    "            poscount3 = 0  # 积极词的最后分值（包括叹号的分值）\n",
    "            negcount = 0\n",
    "            negcount2 = 0\n",
    "            negcount3 = 0\n",
    "            for word in segtmp:\n",
    "                if word in self.Poss:  # 判断词语是否是情感词\n",
    "                    poscount += 1\n",
    "                    c = 0\n",
    "                    for w in segtmp[a:i]:  # 扫描情感词前的程度词\n",
    "                        if w in self.Extremes:\n",
    "                            poscount *= 4.0\n",
    "                        elif w in self.Verys:\n",
    "                            poscount *= 3.0\n",
    "                        elif w in self.Mores:\n",
    "                            poscount *= 2.0\n",
    "                        elif w in self.Ishs:\n",
    "                            poscount *= 0.5\n",
    "                        elif w in self.Denys:\n",
    "                            c += 1\n",
    "                    if self.judgeodd(c) == 'odd':  # 扫描情感词前的否定词数\n",
    "                        poscount *= -1.0\n",
    "                        poscount2 += poscount\n",
    "                        poscount = 0\n",
    "                        poscount3 = poscount + poscount2 + poscount3\n",
    "                        poscount2 = 0\n",
    "                    else:\n",
    "                        poscount3 = poscount + poscount2 + poscount3\n",
    "                        poscount = 0\n",
    "                    a = i + 1  # 情感词的位置变化\n",
    "\n",
    "                elif word in self.Negs:  # 消极情感的分析，与上面一致\n",
    "                    negcount += 1\n",
    "                    d = 0\n",
    "                    for w in segtmp[a:i]:\n",
    "                        if w in self.Extremes:\n",
    "                            negcount *= 4.0\n",
    "                        elif w in self.Verys:\n",
    "                            negcount *= 3.0\n",
    "                        elif w in self.Mores:\n",
    "                            negcount *= 2.0\n",
    "                        elif w in self.Ishs:\n",
    "                            negcount *= 0.5\n",
    "                        elif w in self.Denys:\n",
    "                            d += 1\n",
    "                    if self.judgeodd(d) == 'odd':\n",
    "                        negcount *= -1.0\n",
    "                        negcount2 += negcount\n",
    "                        negcount = 0\n",
    "                        negcount3 = negcount + negcount2 + negcount3\n",
    "                        negcount2 = 0\n",
    "                    else:\n",
    "                        negcount3 = negcount + negcount2 + negcount3\n",
    "                        negcount = 0\n",
    "                    a = i + 1\n",
    "                elif word == '！' or word == '!':  ##判断句子是否有感叹号\n",
    "                    for w2 in segtmp[::-1]:  # 扫描感叹号前的情感词，发现后权值+2，然后退出循环\n",
    "                        if w2 in self.Poss or self.Negs:\n",
    "                            poscount3 += 2\n",
    "                            negcount3 += 2\n",
    "                            break\n",
    "                i += 1  # 扫描词位置前移\n",
    "\n",
    "                # 以下是防止出现负数的情况\n",
    "                pos_count = 0\n",
    "                neg_count = 0\n",
    "                if poscount3 < 0 and negcount3 > 0:\n",
    "                    neg_count += negcount3 - poscount3\n",
    "                    pos_count = 0\n",
    "                elif negcount3 < 0 and poscount3 > 0:\n",
    "                    pos_count = poscount3 - negcount3\n",
    "                    neg_count = 0\n",
    "                elif poscount3 < 0 and negcount3 < 0:\n",
    "                    neg_count = -poscount3\n",
    "                    pos_count = -negcount3\n",
    "                else:\n",
    "                    pos_count = poscount3\n",
    "                    neg_count = negcount3\n",
    "\n",
    "                count1.append([pos_count, neg_count])\n",
    "            count2.append(count1)\n",
    "            count1 = []\n",
    "\n",
    "        pos_result = []\n",
    "        neg_result = []\n",
    "        for sentence in count2:\n",
    "            score_array = np.array(sentence)\n",
    "            pos = np.sum(score_array[:, 0])\n",
    "            neg = np.sum(score_array[:, 1])\n",
    "            pos_result.append(pos)\n",
    "            neg_result.append(neg)\n",
    "\n",
    "        pos_score = np.sum(np.array(pos_result))\n",
    "        neg_score = np.sum(np.array(neg_result))\n",
    "        score = {'sentences': len(count2),\n",
    "                 'words':wordnum,\n",
    "                 'pos': pos_score,\n",
    "                 'neg': neg_score}\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\zhang\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.896 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 22, 'sentences': 2, 'pos': 4, 'neg': 0}\n",
      "{'sentences': 2, 'words': 22, 'pos': 27.0, 'neg': 0.0}\n"
     ]
    }
   ],
   "source": [
    "test_text= '我好开心啊，非常非常非常高兴！今天我得了一百分，我很兴奋开心，愉快，开心'\n",
    "print(senti.sentiment_count(test_text))\n",
    "print(senti.sentiment_calculate(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
